{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e992947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def feedforward(inputs, weights, biases):\n",
    "    net_inputs = np.dot(weights, inputs) + biases\n",
    "    return sigmoid(net_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0f0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(inputs, targets, outputs, weights, lr):\n",
    "    error = targets - outputs\n",
    "    delta = error * outputs * (1 - outputs)\n",
    "    delta_weights = lr * np.outer(delta, inputs)\n",
    "    new_weights = weights + delta_weights\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59490b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    nx = int(input(\"Enter the number of input neurons: \"))\n",
    "    n_H = int(input(\"Enter the number of hidden neurons: \"))\n",
    "    n_z = int(input(\"Enter the number of output neurons: \"))\n",
    "    lr = float(input(\"Enter the learning rate: \"))\n",
    "\n",
    "    # Initialize weights and biases\n",
    "    wji = np.zeros((n_H, nx))\n",
    "    wkj = np.zeros((n_z, n_H))\n",
    "    biases_j = np.zeros(n_H)\n",
    "    biases_k = np.zeros(n_z)\n",
    "\n",
    "    # Input values for weights wji\n",
    "    print(\"Enter weights for wji:\")\n",
    "    for i in range(n_H):\n",
    "        for j in range(nx):\n",
    "            wji[i][j] = float(input(f\"wji[{i + 1}][{j + 1}]: \"))\n",
    "\n",
    "    # Input values for weights wkj\n",
    "    print(\"Enter weights for wkj:\")\n",
    "    for i in range(n_z):\n",
    "        for j in range(n_H):\n",
    "            wkj[i][j] = float(input(f\"wkj[{i + 1}][{j + 1}]: \"))\n",
    "\n",
    "    # Input values for biases biases_j\n",
    "    print(\"Enter biases for hidden layer:\")\n",
    "    for i in range(n_H):\n",
    "        biases_j[i] = float(input(f\"biases_j[{i + 1}]: \"))\n",
    "\n",
    "    # Input values for biases biases_k\n",
    "    print(\"Enter biases for output layer:\")\n",
    "    for i in range(n_z):\n",
    "        biases_k[i] = float(input(f\"biases_k[{i + 1}]: \"))\n",
    "\n",
    "    # Input values\n",
    "    x = np.array([float(input(f\"Enter value for x[{i + 1}]: \")) for i in range(nx)])\n",
    "    z_target = np.array([float(input(f\"Enter target value for z[{i + 1}]: \")) for i in range(n_z)])\n",
    "\n",
    "    # Feedforward\n",
    "    y = feedforward(x, wji, biases_j)\n",
    "    z = feedforward(y, wkj, biases_k)\n",
    "\n",
    "    # Calculate initial error\n",
    "    error = 0.5 * np.sum((z - z_target) ** 2)\n",
    "    print(\"Initial Error:\", error)\n",
    "\n",
    "    # Backpropagation\n",
    "    delta_k = (z - z_target) * z * (1 - z)\n",
    "    delta_j = y * (1 - y) * np.dot(wkj.T, delta_k)\n",
    "\n",
    "    # Update weights and biases\n",
    "    wkj = backpropagation(y, z_target, z, wkj, lr)\n",
    "    wji = backpropagation(x, delta_j, y, wji, lr)\n",
    "    biases_k -= lr * delta_k\n",
    "    biases_j -= lr * delta_j\n",
    "\n",
    "    # Feedforward again with updated weights and biases\n",
    "    y = feedforward(x, wji, biases_j)\n",
    "    z = feedforward(y, wkj, biases_k)\n",
    "\n",
    "    # Calculate updated error\n",
    "    error = 0.5 * np.sum((z - z_target) ** 2)\n",
    "    print(\"Updated Error:\", error)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the number of iterations: 10\n",
    "# Enter the number of input neurons: 3\n",
    "# Enter the number of hidden neurons: 2\n",
    "# Enter the number of output neurons: 1\n",
    "# Enter the learning rate: 0.75\n",
    "# Enter weights for wji:\n",
    "# wji[1][1]: 0.2\n",
    "# wji[1][2]: 0.3\n",
    "# wji[1][3]: 0.1\n",
    "# wji[2][1]: 0.1\n",
    "# wji[2][2]: -0.1\n",
    "# wji[2][3]: 0.2\n",
    "# Enter weights for wkj:\n",
    "# wkj[1][1]: 0.1\n",
    "# wkj[1][2]: 0.5\n",
    "# Enter biases for hidden layer:\n",
    "# biases_j[1]: 0\n",
    "# biases_j[2]: 0\n",
    "# Enter biases for output layer:\n",
    "# biases_k[1]: 0\n",
    "# Enter value for x[1]: 1\n",
    "# Enter value for x[2]: 0.4\n",
    "# Enter value for x[3]: 0.7\n",
    "# Enter target value for z[1]: 0.65\n",
    "# Error: 0.0023441587447317197\n",
    "# Error: 0.0024329309447956803\n",
    "# Error: 0.002507193898135982\n",
    "# Error: 0.002559045673980632\n",
    "# Error: 0.0025851289021876543\n",
    "# Error: 0.0025855497172263095\n",
    "# Error: 0.002562590969810812\n",
    "# Error: 0.0025196256756886385\n",
    "# Error: 0.0024603623828744594\n",
    "# Error: 0.0023883932179558417"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
